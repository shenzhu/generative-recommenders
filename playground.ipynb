{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "from datetime import date\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import gin\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from generative_recommenders.research.data.eval import (\n",
    "    _avg,\n",
    "    add_to_summary_writer,\n",
    "    eval_metrics_v2_from_tensors,\n",
    "    get_eval_state,\n",
    ")\n",
    "\n",
    "from generative_recommenders.research.data.reco_dataset import get_reco_dataset\n",
    "from generative_recommenders.research.indexing.utils import get_top_k_module\n",
    "from generative_recommenders.research.modeling.sequential.autoregressive_losses import (\n",
    "    BCELoss,\n",
    "    InBatchNegativesSampler,\n",
    "    LocalNegativesSampler,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.embedding_modules import (\n",
    "    EmbeddingModule,\n",
    "    LocalEmbeddingModule,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.encoder_utils import (\n",
    "    get_sequential_encoder,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.features import (\n",
    "    movielens_seq_features_from_row,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.input_features_preprocessors import (\n",
    "    LearnablePositionalEmbeddingInputFeaturesPreprocessor,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.losses.sampled_softmax import (\n",
    "    SampledSoftmaxLoss,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.output_postprocessors import (\n",
    "    L2NormEmbeddingPostprocessor,\n",
    "    LayerNormEmbeddingPostprocessor,\n",
    ")\n",
    "from generative_recommenders.research.modeling.similarity_utils import (\n",
    "    get_similarity_function,\n",
    ")\n",
    "from generative_recommenders.research.trainer.data_loader import create_data_loader\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank: int = 0\n",
    "world_size: int = 1\n",
    "master_port: int = 12355\n",
    "dataset_name: str = \"ml-1m\"\n",
    "max_sequence_length: int = 200\n",
    "positional_sampling_ratio: float = 1.0\n",
    "local_batch_size: int = 128\n",
    "eval_batch_size: int = 128\n",
    "eval_user_max_batch_size: Optional[int] = None\n",
    "main_module: str = \"HSTU\"\n",
    "main_module_bf16: bool = False\n",
    "dropout_rate: float = 0.2\n",
    "user_embedding_norm: str = \"l2_norm\"\n",
    "sampling_strategy: str = \"in-batch\"\n",
    "loss_module: str = \"SampledSoftmaxLoss\"\n",
    "loss_weights: Optional[Dict[str, float]] = {}\n",
    "num_negatives: int = 1\n",
    "loss_activation_checkpoint: bool = False\n",
    "item_l2_norm: bool = False\n",
    "temperature: float = 0.05\n",
    "num_epochs: int = 101\n",
    "learning_rate: float = 1e-3\n",
    "num_warmup_steps: int = 0\n",
    "weight_decay: float = 1e-3\n",
    "top_k_method: str = \"MIPSBruteForceTopK\"\n",
    "eval_interval: int = 100\n",
    "full_eval_every_n: int = 1\n",
    "save_ckpt_every_n: int = 1000\n",
    "partial_eval_num_iters: int = 32\n",
    "embedding_module_type: str = \"local\"\n",
    "item_embedding_dim: int = 240\n",
    "interaction_module_type: str = \"\"\n",
    "gr_output_length: int = 10\n",
    "l2_norm_eps: float = 1e-6\n",
    "enable_tf32: bool = False\n",
    "random_seed: int = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-1m\n"
     ]
    }
   ],
   "source": [
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_reco_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    max_sequence_length=max_sequence_length,\n",
    "    chronological=True,\n",
    "    positional_sampling_ratio=positional_sampling_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sampler, train_data_loader = create_data_loader(\n",
    "    dataset.train_dataset,\n",
    "    batch_size=local_batch_size,\n",
    "    world_size=world_size,\n",
    "    rank=rank,\n",
    "    shuffle=True,\n",
    "    drop_last=world_size > 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.distributed.DistributedSampler'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data_sampler))\n",
    "print(type(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_id', 'historical_ids', 'historical_ratings', 'historical_timestamps', 'history_lengths', 'target_ids', 'target_ratings', 'target_timestamps'])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_data_loader))\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = batch[\"user_id\"]\n",
    "historical_ids = batch[\"historical_ids\"]\n",
    "historical_ratings = batch[\"historical_ratings\"]\n",
    "historical_timestamps = batch[\"historical_timestamps\"]\n",
    "history_lengths = batch[\"history_lengths\"]\n",
    "target_ids = batch[\"target_ids\"]\n",
    "target_ratings = batch[\"target_ratings\"]\n",
    "target_timestamps = batch[\"target_timestamps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([5536, 4688,  343,  238, 3595, 5447, 5372,  100, 3076, 5615, 2641, 2955,\n",
      "        4430, 2527, 3897, 1687, 1807, 2045,  576, 5661, 5854, 3005, 4033,  595,\n",
      "        2914, 1539, 1366,  866, 3014, 2250, 2656,  232, 3272,  181, 4890, 3320,\n",
      "        4363, 1465, 2409,  113, 5925, 4348, 5381, 2156, 5380, 1091, 5383, 4141,\n",
      "        5848, 3424, 2565, 5841, 5050, 2731,  708,  142,  365,  404, 3000, 1471,\n",
      "        5816,  677, 4309,  290, 1510, 5939, 2843, 2298, 3725,  141, 2496, 1430,\n",
      "        1741, 2978, 5206, 5820, 2880,  535, 5026,  437,  291, 3708,  983, 4030,\n",
      "        3499, 2196,  855, 3347, 2229, 2121, 4856, 2485, 4361,    9, 2989, 2524,\n",
      "        5482, 1160, 4591,  783, 2697, 3810, 4446, 5129, 5956, 1296, 2366, 3101,\n",
      "        3295, 3665, 1369, 5983, 2546,  884,  797, 4967, 4228, 5587, 5144, 2048,\n",
      "        3768,  944,  665, 3865, 3891,  720, 3213, 5435])\n"
     ]
    }
   ],
   "source": [
    "print(user_id.shape)\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 200])\n",
      "tensor([2676, 3528,   31, 3436,  605, 1726, 1609,  277,  458, 2264, 3270, 3437,\n",
      "        2005,    2, 2021, 1702,  541, 1344, 1748, 2672, 3476, 1258, 1997, 1994,\n",
      "        3499, 1982, 2455, 1407, 2710, 1332, 2459, 1347, 1339, 1974, 1327,  879,\n",
      "        2004, 1762,  742, 2121, 2513, 2717,  196, 1970, 2122, 1977, 2315, 1380,\n",
      "        1088, 1086, 1964, 1459, 1625, 2583, 1092, 1464, 1892, 2752,  695, 2413,\n",
      "         924, 1247,  377,  802, 1059, 3479, 3501, 1216, 2581, 2340, 1755,  289,\n",
      "        1835,  249,  163,  461,  236, 2802, 2369, 3394, 2875,  804, 2950, 1556,\n",
      "         750, 1199, 1240, 2010,  589,  198, 2407, 2527, 1921, 1603,  316,  185,\n",
      "         442, 3033,  611, 3354, 1037,  172,  256,  880, 2701, 1882,  319,  373,\n",
      "        3147, 2819, 1834, 2391, 3203, 3102, 3518, 3505, 2118,  832, 3176, 3101,\n",
      "        2058, 3555, 2707, 2353, 1608,  422,  490, 1722,   16, 3686, 3005, 1422,\n",
      "        2273,  376, 1518, 3370, 3219, 2881, 1597,  230, 1438, 2956, 1047, 3557,\n",
      "        2803,  225, 1686, 1687, 2561, 2263, 2505, 1658,   23, 3316,  415,   79,\n",
      "        2605,  782, 1831, 1752, 1299, 2402, 2404, 1266, 3671,  383,  416,  648,\n",
      "        1573,  553, 3571, 3481,  951, 3626, 2997, 2249, 2861, 2912, 3115, 3717,\n",
      "        2433, 3683, 1542, 2826, 2976, 3007, 3755, 3785, 3752, 3646, 3825, 3616,\n",
      "        3826, 3827, 3793, 3298, 1136, 1080, 2443, 2731])\n"
     ]
    }
   ],
   "source": [
    "print(historical_ids.shape)\n",
    "print(historical_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 200])\n",
      "tensor([3, 3, 2, 2, 2, 1, 3, 2, 3, 2, 4, 1, 1, 2, 2, 1, 4, 2, 3, 3, 4, 4, 4, 1,\n",
      "        3, 3, 1, 3, 4, 2, 2, 2, 1, 3, 3, 3, 1, 2, 1, 1, 3, 1, 2, 3, 1, 1, 1, 3,\n",
      "        2, 3, 3, 3, 5, 3, 3, 4, 3, 2, 3, 1, 5, 3, 4, 2, 4, 3, 4, 3, 3, 1, 3, 3,\n",
      "        3, 3, 2, 3, 1, 2, 2, 2, 1, 3, 1, 1, 5, 4, 4, 3, 4, 3, 3, 4, 3, 2, 2, 2,\n",
      "        2, 2, 1, 4, 2, 1, 2, 2, 2, 1, 3, 4, 4, 5, 3, 4, 3, 3, 2, 4, 3, 3, 4, 3,\n",
      "        3, 4, 4, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3,\n",
      "        2, 3, 3, 2, 3, 3, 3, 3, 1, 2, 1, 3, 3, 3, 3, 2, 4, 3, 2, 3, 4, 3, 1, 2,\n",
      "        4, 3, 4, 3, 1, 1, 3, 2, 4, 4, 3, 4, 5, 4, 2, 2, 4, 5, 4, 2, 3, 2, 2, 4,\n",
      "        1, 4, 5, 5, 1, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(historical_ratings.shape)\n",
    "print(historical_ratings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 200])\n",
      "tensor([963617959, 963617985, 963617985, 963617985, 963618003, 963618093,\n",
      "        963618093, 963618093, 963618116, 963618136, 963618179, 963618179,\n",
      "        963618179, 963618196, 963618216, 963618266, 963618299, 963618331,\n",
      "        963618350, 963618375, 963618375, 963618414, 963618414, 963618414,\n",
      "        963618414, 963618414, 963618450, 963618450, 963618495, 963618565,\n",
      "        963618565, 963618583, 963618583, 963618600, 963618600, 963618648,\n",
      "        963618648, 963618648, 963618670, 963618670, 963618670, 963618693,\n",
      "        963618693, 963618729, 963618748, 963618760, 963618781, 963618781,\n",
      "        963618781, 963618815, 963618815, 963618987, 963619024, 963619071,\n",
      "        963619071, 963619071, 963619099, 963619099, 963619099, 963619129,\n",
      "        963619129, 963619129, 963619129, 963619129, 963619129, 963619153,\n",
      "        963619153, 963619181, 963619181, 963619181, 963619246, 963619246,\n",
      "        963619246, 963619246, 963619246, 963619246, 963619289, 963619289,\n",
      "        963619289, 963619335, 963619335, 963619335, 963619335, 963619365,\n",
      "        963619365, 963619416, 963619416, 963619417, 963619434, 963619452,\n",
      "        963619540, 963619540, 963619567, 963619567, 963619567, 963619600,\n",
      "        963619642, 963619657, 963619657, 963619679, 963619701, 963619701,\n",
      "        963619729, 963619729, 963619729, 963619743, 963619771, 963619771,\n",
      "        963619771, 963619786, 963619807, 963619824, 963619845, 963619871,\n",
      "        963619908, 963619929, 963619954, 963619954, 963619975, 963620091,\n",
      "        963620091, 963678663, 963678683, 963678734, 963678749, 963678831,\n",
      "        963678850, 963678850, 963678869, 963679358,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0])\n"
     ]
    }
   ],
   "source": [
    "print(historical_timestamps.shape)\n",
    "print(historical_timestamps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([200, 130, 200, 200,  29, 129,  34,  74,  20, 200, 200, 189, 200,  19,\n",
      "         19, 200, 200,  23,  55, 123, 200, 109, 200,  98,  70,  25, 141,  34,\n",
      "        168,  65, 130,  88, 200, 200, 169, 200, 190, 200, 132,  66, 195,  22,\n",
      "         22, 200,  18,  31,  26, 200, 200,  69, 200, 200,  83, 200,  18,  45,\n",
      "         45,  48, 104,  25,  30, 200, 130,  31,  31, 109,  37, 118,  24,  21,\n",
      "        200, 114, 200, 171,  27,  46, 200,  19, 200,  50, 100,  33,  76, 122,\n",
      "        200,  34, 200,  43,  37, 189,  77, 200, 130, 104, 103,  24, 200, 105,\n",
      "        200, 117,  32,  65, 200, 108, 200,  46,  39, 200,  72, 200, 200,  26,\n",
      "        116,  97,  81, 102,  21,  53,  30,  33, 200,  43,  18,  55,  98, 200,\n",
      "        135,  44])\n",
      "tensor(200)\n"
     ]
    }
   ],
   "source": [
    "print(history_lengths.shape)\n",
    "print(history_lengths)\n",
    "print(max(history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([ 423, 1639, 2498, 3420, 3005, 3604, 3317,  265, 1722, 1242, 2374, 3328,\n",
      "        2953, 1287, 2359, 2013,  208, 2881, 1956, 2355, 1980, 1371, 3869,  454,\n",
      "        1923,  898, 2739, 3510, 2431, 3745, 2018, 2567, 1606, 3246,  515, 1326,\n",
      "         457, 1928, 2067, 3883, 1230, 3811, 2791, 1681, 2836,  648,  750, 1552,\n",
      "         303, 2706, 3831,  921, 3285, 2133, 3675, 2761, 2762, 3159, 2950,  268,\n",
      "        1092, 3230, 3186, 1188, 2456, 3481, 2668,    3, 3386, 3469, 1278, 1251,\n",
      "         417, 1256, 1954, 1265, 1235, 3114, 3649, 3836, 1936, 3846, 3701, 2144,\n",
      "        2121, 3300, 2245, 3006, 3263, 1207, 2700, 3115, 2761,  367, 1371, 1219,\n",
      "        3686, 2714,  549, 2141, 2070, 2922,  181,  377, 3906, 1307,  368, 1243,\n",
      "         587, 2124, 2158, 2528, 3189,   34,  969, 3821,  593,  337, 1088, 1252,\n",
      "        3442,  318, 1219, 1081, 2928,  733, 1231,   24])\n"
     ]
    }
   ],
   "source": [
    "print(target_ids.shape)\n",
    "print(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([3, 5, 3, 4, 3, 5, 3, 3, 3, 4, 2, 4, 1, 5, 5, 5, 2, 3, 4, 3, 2, 2, 4, 5,\n",
      "        5, 4, 5, 5, 3, 4, 5, 1, 3, 5, 4, 2, 5, 4, 5, 1, 4, 5, 4, 2, 3, 3, 5, 3,\n",
      "        2, 4, 4, 3, 3, 4, 4, 4, 5, 4, 1, 4, 3, 4, 4, 2, 3, 5, 2, 2, 2, 5, 5, 5,\n",
      "        4, 4, 4, 2, 5, 5, 2, 5, 4, 3, 3, 5, 3, 4, 4, 5, 3, 4, 3, 4, 3, 3, 1, 4,\n",
      "        4, 4, 3, 3, 5, 4, 1, 4, 3, 5, 2, 5, 4, 4, 5, 4, 4, 5, 5, 3, 4, 4, 5, 5,\n",
      "        2, 5, 5, 2, 3, 3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "print(target_ratings.shape)\n",
    "print(target_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([1003623343,  963679419, 1044805014,  976767198,  966630460,  996013330,\n",
      "         961607731,  977594963,  969851412,  959307449, 1028484651,  971207152,\n",
      "         965106138,  974058435,  965779227,  974714308,  974742329,  974668616,\n",
      "         976063418,  958780306,  958346913,  970569489,  966208707,  975898200,\n",
      "         971763054,  981396825,  974778476,  975277824, 1013919071,  974596665,\n",
      "         973531539,  976812980,  971259833,  977090726,  962740343,  970861801,\n",
      "         965186085,  974768388, 1008702921,  977507339,  959186558,  965485055,\n",
      "         960928975,  974632724,  960393128,  974930242,  960355691,  965353589,\n",
      "         957786013,  967359392,  996354386, 1037881424,  983492534,  973244412,\n",
      "         975542300,  980559291,  976405459,  985827325,  970622299,  974753567,\n",
      "         957915227,  975612817,  967745654,  976564993,  974749071,  957216437,\n",
      "         972545433,  974500185,  966218328,  977357662,  974435324,  974761580,\n",
      "         974712244,  970968986,  961631084,  957905722,  989193365,  976139053,\n",
      "         962777729,  976278578,  976566560,  966278986,  975102416,  983753078,\n",
      "         967235253,  974606442,  976426485,  967757542,  974598284,  974648496,\n",
      "         962831789, 1026162329,  984248355,  978226678,  970889766,  974064506,\n",
      "         960389765, 1008037748, 1043098047,  984413494,  973307036,  965959151,\n",
      "         965543296,  962134969, 1026249529,  974788874,  974340915,  970451909,\n",
      "         968058324,  993858589, 1014452563,  956926305,  974041727, 1019867791,\n",
      "         975414339,  967979486,  965313576,  959283008,  962035715,  974664355,\n",
      "        1000107195,  975166495,  975645686,  965853709,  965802710,  975530188,\n",
      "         968520476,  960062286])\n"
     ]
    }
   ],
   "source": [
    "print(target_timestamps.shape)\n",
    "print(target_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model and moves it to GPU with id rank\n",
    "device = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features, target_ids, target_ratings = movielens_seq_features_from_row(\n",
    "    batch,\n",
    "    device=device,\n",
    "    max_output_length=gr_output_length + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1])\n",
      "tensor([[ 423],\n",
      "        [1639],\n",
      "        [2498],\n",
      "        [3420],\n",
      "        [3005]], device='cuda:0')\n",
      "torch.Size([128, 1])\n",
      "tensor([[3],\n",
      "        [5],\n",
      "        [3],\n",
      "        [4],\n",
      "        [3]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(target_ids.shape)\n",
    "print(target_ids[:5])\n",
    "print(target_ratings.shape)\n",
    "print(target_ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128, 211])\n",
      "None\n",
      "torch.Size([128, 211])\n",
      "torch.Size([128, 211])\n"
     ]
    }
   ],
   "source": [
    "print(seq_features.past_lengths.shape)\n",
    "print(seq_features.past_ids.shape)\n",
    "print(seq_features.past_embeddings.shape if seq_features.past_embeddings else None)\n",
    "print(seq_features.past_payloads[\"timestamps\"].shape)\n",
    "print(seq_features.past_payloads[\"ratings\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "print(dataset.max_item_id)\n",
    "print(item_embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize _item_emb.weight as truncated normal: torch.Size([3953, 240]) params\n"
     ]
    }
   ],
   "source": [
    "embedding_module: EmbeddingModule = LocalEmbeddingModule(\n",
    "    num_items=dataset.max_item_id,\n",
    "    item_embedding_dim=item_embedding_dim\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local_emb_d240'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_module.debug_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_item_emb.weight: torch.Size([3953, 240])\n"
     ]
    }
   ],
   "source": [
    "for name, params in embedding_module.named_parameters():\n",
    "    print(f\"{name}: {params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "B, N = seq_features.past_ids.shape\n",
    "print(B)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2676, 3528,   31,  ...,    0,    0,    0],\n",
       "        [1711, 1254, 1196,  ...,    0,    0,    0],\n",
       "        [1136, 1278, 2394,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [2000, 1201, 1222,  ...,    0,    0,    0],\n",
       "        [ 480, 1777, 2359,  ...,    0,    0,    0],\n",
       "        [1358, 1230,  480,  ...,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_features.past_ids.scatter_(\n",
    "    dim=1,\n",
    "    index=seq_features.past_lengths.view(-1, 1),\n",
    "    src=target_ids.view(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = embedding_module.get_item_embeddings(seq_features.past_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 211, 240])\n"
     ]
    }
   ],
   "source": [
    "# batch x seq x dim\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "10\n",
      "240\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# for max_sequence_len\n",
    "print(dataset.max_sequence_length)\n",
    "print(gr_output_length)\n",
    "\n",
    "# for embedding_dim\n",
    "print(item_embedding_dim)\n",
    "\n",
    "# for dropout_rate\n",
    "print(dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posi_d0.2'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_preproc_module = LearnablePositionalEmbeddingInputFeaturesPreprocessor(\n",
    "    max_sequence_len=dataset.max_sequence_length + gr_output_length + 1,\n",
    "    embedding_dim=item_embedding_dim,\n",
    "    dropout_rate=dropout_rate,\n",
    ").to(device)\n",
    "\n",
    "input_preproc_module.debug_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_lengths, user_embeddings, _ = input_preproc_module(\n",
    "    past_lengths=seq_features.past_lengths,\n",
    "    past_ids=seq_features.past_ids,\n",
    "    past_embeddings=input_embeddings,\n",
    "    past_payloads=seq_features.past_payloads,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128, 211, 240])\n"
     ]
    }
   ],
   "source": [
    "print(past_lengths.shape)\n",
    "print(user_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

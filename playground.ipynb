{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "from datetime import date\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import gin\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from generative_recommenders.research.data.eval import (\n",
    "    _avg,\n",
    "    add_to_summary_writer,\n",
    "    eval_metrics_v2_from_tensors,\n",
    "    get_eval_state,\n",
    ")\n",
    "\n",
    "from generative_recommenders.research.data.reco_dataset import get_reco_dataset\n",
    "from generative_recommenders.research.indexing.utils import get_top_k_module\n",
    "from generative_recommenders.research.modeling.sequential.autoregressive_losses import (\n",
    "    BCELoss,\n",
    "    InBatchNegativesSampler,\n",
    "    LocalNegativesSampler,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.embedding_modules import (\n",
    "    EmbeddingModule,\n",
    "    LocalEmbeddingModule,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.encoder_utils import (\n",
    "    get_sequential_encoder,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.features import (\n",
    "    movielens_seq_features_from_row,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.input_features_preprocessors import (\n",
    "    LearnablePositionalEmbeddingInputFeaturesPreprocessor,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.losses.sampled_softmax import (\n",
    "    SampledSoftmaxLoss,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.output_postprocessors import (\n",
    "    L2NormEmbeddingPostprocessor,\n",
    "    LayerNormEmbeddingPostprocessor,\n",
    ")\n",
    "from generative_recommenders.research.modeling.similarity_utils import (\n",
    "    get_similarity_function,\n",
    ")\n",
    "from generative_recommenders.research.trainer.data_loader import create_data_loader\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank: int = 0\n",
    "world_size: int = 1\n",
    "master_port: int = 12355\n",
    "dataset_name: str = \"ml-1m\"\n",
    "max_sequence_length: int = 200\n",
    "positional_sampling_ratio: float = 1.0\n",
    "local_batch_size: int = 128\n",
    "eval_batch_size: int = 128\n",
    "eval_user_max_batch_size: Optional[int] = None\n",
    "main_module: str = \"SASRec\"\n",
    "main_module_bf16: bool = False\n",
    "dropout_rate: float = 0.2\n",
    "user_embedding_norm: str = \"l2_norm\"\n",
    "sampling_strategy: str = \"in-batch\"\n",
    "loss_module: str = \"SampledSoftmaxLoss\"\n",
    "loss_weights: Optional[Dict[str, float]] = {}\n",
    "num_negatives: int = 1\n",
    "loss_activation_checkpoint: bool = False\n",
    "item_l2_norm: bool = False\n",
    "temperature: float = 0.05\n",
    "num_epochs: int = 101\n",
    "learning_rate: float = 1e-3\n",
    "num_warmup_steps: int = 0\n",
    "weight_decay: float = 1e-3\n",
    "top_k_method: str = \"MIPSBruteForceTopK\"\n",
    "eval_interval: int = 100\n",
    "full_eval_every_n: int = 1\n",
    "save_ckpt_every_n: int = 1000\n",
    "partial_eval_num_iters: int = 32\n",
    "embedding_module_type: str = \"local\"\n",
    "item_embedding_dim: int = 240\n",
    "interaction_module_type: str = \"\"\n",
    "gr_output_length: int = 10\n",
    "l2_norm_eps: float = 1e-6\n",
    "enable_tf32: bool = False\n",
    "random_seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-1m\n"
     ]
    }
   ],
   "source": [
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_reco_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    max_sequence_length=max_sequence_length,\n",
    "    chronological=True,\n",
    "    positional_sampling_ratio=positional_sampling_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sampler, train_data_loader = create_data_loader(\n",
    "    dataset.train_dataset,\n",
    "    batch_size=local_batch_size,\n",
    "    world_size=world_size,\n",
    "    rank=rank,\n",
    "    shuffle=True,\n",
    "    drop_last=world_size > 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.distributed.DistributedSampler'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data_sampler))\n",
    "print(type(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 data type: <class 'dict'>\n",
      "batch 1 data shape: None\n",
      "batch 1\n",
      "  key: user_id\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128])\n",
      "    data: tensor([5536, 4688,  343,  238, 3595, 5447, 5372,  100, 3076, 5615, 2641, 2955,\n",
      "        4430, 2527, 3897, 1687, 1807, 2045,  576, 5661, 5854, 3005, 4033,  595,\n",
      "        2914, 1539, 1366,  866, 3014, 2250, 2656,  232, 3272,  181, 4890, 3320,\n",
      "        4363, 1465, 2409,  113, 5925, 4348, 5381, 2156, 5380, 1091, 5383, 4141,\n",
      "        5848, 3424, 2565, 5841, 5050, 2731,  708,  142,  365,  404, 3000, 1471,\n",
      "        5816,  677, 4309,  290, 1510, 5939, 2843, 2298, 3725,  141, 2496, 1430,\n",
      "        1741, 2978, 5206, 5820, 2880,  535, 5026,  437,  291, 3708,  983, 4030,\n",
      "        3499, 2196,  855, 3347, 2229, 2121, 4856, 2485, 4361,    9, 2989, 2524,\n",
      "        5482, 1160, 4591,  783, 2697, 3810, 4446, 5129, 5956, 1296, 2366, 3101,\n",
      "        3295, 3665, 1369, 5983, 2546,  884,  797, 4967, 4228, 5587, 5144, 2048,\n",
      "        3768,  944,  665, 3865, 3891,  720, 3213, 5435])\n",
      "  key: historical_ids\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128, 200])\n",
      "    data: tensor([[2676, 3528,   31,  ..., 1080, 2443, 2731],\n",
      "        [1711, 1254, 1196,  ...,    0,    0,    0],\n",
      "        [1136, 1278, 2394,  ...,  500, 2617, 1569],\n",
      "        ...,\n",
      "        [2000, 1201, 1222,  ..., 2046,  421, 2005],\n",
      "        [ 480, 1777, 2359,  ...,    0,    0,    0],\n",
      "        [1358, 1230,  480,  ...,    0,    0,    0]])\n",
      "  key: historical_ratings\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128, 200])\n",
      "    data: tensor([[3, 3, 2,  ..., 2, 4, 1],\n",
      "        [3, 5, 5,  ..., 0, 0, 0],\n",
      "        [5, 5, 5,  ..., 4, 4, 4],\n",
      "        ...,\n",
      "        [3, 4, 4,  ..., 2, 2, 4],\n",
      "        [2, 4, 4,  ..., 0, 0, 0],\n",
      "        [5, 5, 4,  ..., 0, 0, 0]])\n",
      "  key: historical_timestamps\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128, 200])\n",
      "    data: tensor([[ 959816488,  959816501,  959816515,  ..., 1003623191, 1003623292,\n",
      "         1003623343],\n",
      "        [ 963617959,  963617985,  963617985,  ...,          0,          0,\n",
      "                  0],\n",
      "        [ 996005276,  996005291,  996092911,  ..., 1044804296, 1044804326,\n",
      "         1044804974],\n",
      "        ...,\n",
      "        [ 975527599,  975527599,  975527599,  ...,  975530157,  975530157,\n",
      "          975530163],\n",
      "        [ 968517165,  968517166,  968517166,  ...,          0,          0,\n",
      "                  0],\n",
      "        [ 960032742,  960032742,  960032785,  ...,          0,          0,\n",
      "                  0]])\n",
      "  key: history_lengths\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128])\n",
      "    data: tensor([200, 130, 200, 200,  29, 129,  34,  74,  20, 200, 200, 189, 200,  19,\n",
      "         19, 200, 200,  23,  55, 123, 200, 109, 200,  98,  70,  25, 141,  34,\n",
      "        168,  65, 130,  88, 200, 200, 169, 200, 190, 200, 132,  66, 195,  22,\n",
      "         22, 200,  18,  31,  26, 200, 200,  69, 200, 200,  83, 200,  18,  45,\n",
      "         45,  48, 104,  25,  30, 200, 130,  31,  31, 109,  37, 118,  24,  21,\n",
      "        200, 114, 200, 171,  27,  46, 200,  19, 200,  50, 100,  33,  76, 122,\n",
      "        200,  34, 200,  43,  37, 189,  77, 200, 130, 104, 103,  24, 200, 105,\n",
      "        200, 117,  32,  65, 200, 108, 200,  46,  39, 200,  72, 200, 200,  26,\n",
      "        116,  97,  81, 102,  21,  53,  30,  33, 200,  43,  18,  55,  98, 200,\n",
      "        135,  44])\n",
      "  key: target_ids\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128])\n",
      "    data: tensor([ 423, 1639, 2498, 3420, 3005, 3604, 3317,  265, 1722, 1242, 2374, 3328,\n",
      "        2953, 1287, 2359, 2013,  208, 2881, 1956, 2355, 1980, 1371, 3869,  454,\n",
      "        1923,  898, 2739, 3510, 2431, 3745, 2018, 2567, 1606, 3246,  515, 1326,\n",
      "         457, 1928, 2067, 3883, 1230, 3811, 2791, 1681, 2836,  648,  750, 1552,\n",
      "         303, 2706, 3831,  921, 3285, 2133, 3675, 2761, 2762, 3159, 2950,  268,\n",
      "        1092, 3230, 3186, 1188, 2456, 3481, 2668,    3, 3386, 3469, 1278, 1251,\n",
      "         417, 1256, 1954, 1265, 1235, 3114, 3649, 3836, 1936, 3846, 3701, 2144,\n",
      "        2121, 3300, 2245, 3006, 3263, 1207, 2700, 3115, 2761,  367, 1371, 1219,\n",
      "        3686, 2714,  549, 2141, 2070, 2922,  181,  377, 3906, 1307,  368, 1243,\n",
      "         587, 2124, 2158, 2528, 3189,   34,  969, 3821,  593,  337, 1088, 1252,\n",
      "        3442,  318, 1219, 1081, 2928,  733, 1231,   24])\n",
      "  key: target_ratings\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128])\n",
      "    data: tensor([3, 5, 3, 4, 3, 5, 3, 3, 3, 4, 2, 4, 1, 5, 5, 5, 2, 3, 4, 3, 2, 2, 4, 5,\n",
      "        5, 4, 5, 5, 3, 4, 5, 1, 3, 5, 4, 2, 5, 4, 5, 1, 4, 5, 4, 2, 3, 3, 5, 3,\n",
      "        2, 4, 4, 3, 3, 4, 4, 4, 5, 4, 1, 4, 3, 4, 4, 2, 3, 5, 2, 2, 2, 5, 5, 5,\n",
      "        4, 4, 4, 2, 5, 5, 2, 5, 4, 3, 3, 5, 3, 4, 4, 5, 3, 4, 3, 4, 3, 3, 1, 4,\n",
      "        4, 4, 3, 3, 5, 4, 1, 4, 3, 5, 2, 5, 4, 4, 5, 4, 4, 5, 5, 3, 4, 4, 5, 5,\n",
      "        2, 5, 5, 2, 3, 3, 5, 4])\n",
      "  key: target_timestamps\n",
      "    data type: <class 'torch.Tensor'>\n",
      "    data shape: torch.Size([128])\n",
      "    data: tensor([1003623343,  963679419, 1044805014,  976767198,  966630460,  996013330,\n",
      "         961607731,  977594963,  969851412,  959307449, 1028484651,  971207152,\n",
      "         965106138,  974058435,  965779227,  974714308,  974742329,  974668616,\n",
      "         976063418,  958780306,  958346913,  970569489,  966208707,  975898200,\n",
      "         971763054,  981396825,  974778476,  975277824, 1013919071,  974596665,\n",
      "         973531539,  976812980,  971259833,  977090726,  962740343,  970861801,\n",
      "         965186085,  974768388, 1008702921,  977507339,  959186558,  965485055,\n",
      "         960928975,  974632724,  960393128,  974930242,  960355691,  965353589,\n",
      "         957786013,  967359392,  996354386, 1037881424,  983492534,  973244412,\n",
      "         975542300,  980559291,  976405459,  985827325,  970622299,  974753567,\n",
      "         957915227,  975612817,  967745654,  976564993,  974749071,  957216437,\n",
      "         972545433,  974500185,  966218328,  977357662,  974435324,  974761580,\n",
      "         974712244,  970968986,  961631084,  957905722,  989193365,  976139053,\n",
      "         962777729,  976278578,  976566560,  966278986,  975102416,  983753078,\n",
      "         967235253,  974606442,  976426485,  967757542,  974598284,  974648496,\n",
      "         962831789, 1026162329,  984248355,  978226678,  970889766,  974064506,\n",
      "         960389765, 1008037748, 1043098047,  984413494,  973307036,  965959151,\n",
      "         965543296,  962134969, 1026249529,  974788874,  974340915,  970451909,\n",
      "         968058324,  993858589, 1014452563,  956926305,  974041727, 1019867791,\n",
      "         975414339,  967979486,  965313576,  959283008,  962035715,  974664355,\n",
      "        1000107195,  975166495,  975645686,  965853709,  965802710,  975530188,\n",
      "         968520476,  960062286])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_data_loader):\n",
    "    print(f\"batch {i + 1} data type: {type(batch)}\")\n",
    "    print(f\"batch {i + 1} data shape: {batch.shape if isinstance(batch, torch.Tensor) else None}\")\n",
    "    \n",
    "    print(f\"batch {i + 1}\")\n",
    "    for key in batch:\n",
    "        print(f\"  key: {key}\")\n",
    "        print(f\"    data type: {type(batch[key])}\")\n",
    "        print(f\"    data shape: {batch[key].shape if isinstance(batch[key], torch.Tensor) else None}\")\n",
    "        print(f\"    data: {batch[key]}\")\n",
    "\n",
    "    if i >= 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

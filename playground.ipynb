{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "from datetime import date\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import gin\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from generative_recommenders.research.data.eval import (\n",
    "    _avg,\n",
    "    add_to_summary_writer,\n",
    "    eval_metrics_v2_from_tensors,\n",
    "    get_eval_state,\n",
    ")\n",
    "\n",
    "from generative_recommenders.research.data.reco_dataset import get_reco_dataset\n",
    "from generative_recommenders.research.indexing.utils import get_top_k_module\n",
    "from generative_recommenders.research.modeling.sequential.autoregressive_losses import (\n",
    "    BCELoss,\n",
    "    InBatchNegativesSampler,\n",
    "    LocalNegativesSampler,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.embedding_modules import (\n",
    "    EmbeddingModule,\n",
    "    LocalEmbeddingModule,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.encoder_utils import (\n",
    "    get_sequential_encoder,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.features import (\n",
    "    movielens_seq_features_from_row,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.input_features_preprocessors import (\n",
    "    LearnablePositionalEmbeddingInputFeaturesPreprocessor,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.losses.sampled_softmax import (\n",
    "    SampledSoftmaxLoss,\n",
    ")\n",
    "from generative_recommenders.research.modeling.sequential.output_postprocessors import (\n",
    "    L2NormEmbeddingPostprocessor,\n",
    "    LayerNormEmbeddingPostprocessor,\n",
    ")\n",
    "from generative_recommenders.research.modeling.similarity_utils import (\n",
    "    get_similarity_function,\n",
    ")\n",
    "from generative_recommenders.research.trainer.data_loader import create_data_loader\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank: int = 0\n",
    "world_size: int = 1\n",
    "master_port: int = 12355\n",
    "dataset_name: str = \"ml-1m\"\n",
    "max_sequence_length: int = 200\n",
    "positional_sampling_ratio: float = 1.0\n",
    "local_batch_size: int = 128\n",
    "eval_batch_size: int = 128\n",
    "eval_user_max_batch_size: Optional[int] = None\n",
    "main_module: str = \"SASRec\"\n",
    "main_module_bf16: bool = False\n",
    "dropout_rate: float = 0.2\n",
    "user_embedding_norm: str = \"l2_norm\"\n",
    "sampling_strategy: str = \"in-batch\"\n",
    "loss_module: str = \"SampledSoftmaxLoss\"\n",
    "loss_weights: Optional[Dict[str, float]] = {}\n",
    "num_negatives: int = 1\n",
    "loss_activation_checkpoint: bool = False\n",
    "item_l2_norm: bool = False\n",
    "temperature: float = 0.05\n",
    "num_epochs: int = 101\n",
    "learning_rate: float = 1e-3\n",
    "num_warmup_steps: int = 0\n",
    "weight_decay: float = 1e-3\n",
    "top_k_method: str = \"MIPSBruteForceTopK\"\n",
    "eval_interval: int = 100\n",
    "full_eval_every_n: int = 1\n",
    "save_ckpt_every_n: int = 1000\n",
    "partial_eval_num_iters: int = 32\n",
    "embedding_module_type: str = \"local\"\n",
    "item_embedding_dim: int = 240\n",
    "interaction_module_type: str = \"\"\n",
    "gr_output_length: int = 10\n",
    "l2_norm_eps: float = 1e-6\n",
    "enable_tf32: bool = False\n",
    "random_seed: int = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-1m\n"
     ]
    }
   ],
   "source": [
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_reco_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    max_sequence_length=max_sequence_length,\n",
    "    chronological=True,\n",
    "    positional_sampling_ratio=positional_sampling_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sampler, train_data_loader = create_data_loader(\n",
    "    dataset.train_dataset,\n",
    "    batch_size=local_batch_size,\n",
    "    world_size=world_size,\n",
    "    rank=rank,\n",
    "    shuffle=True,\n",
    "    drop_last=world_size > 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.distributed.DistributedSampler'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data_sampler))\n",
    "print(type(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_id', 'historical_ids', 'historical_ratings', 'historical_timestamps', 'history_lengths', 'target_ids', 'target_ratings', 'target_timestamps'])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_data_loader))\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = batch[\"user_id\"]\n",
    "historical_ids = batch[\"historical_ids\"]\n",
    "historical_ratings = batch[\"historical_ratings\"]\n",
    "historical_timestamps = batch[\"historical_timestamps\"]\n",
    "history_lengths = batch[\"history_lengths\"]\n",
    "target_ids = batch[\"target_ids\"]\n",
    "target_ratings = batch[\"target_ratings\"]\n",
    "target_timestamps = batch[\"target_timestamps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([5536, 4688,  343,  238, 3595, 5447, 5372,  100, 3076, 5615, 2641, 2955,\n",
      "        4430, 2527, 3897, 1687, 1807, 2045,  576, 5661, 5854, 3005, 4033,  595,\n",
      "        2914, 1539, 1366,  866, 3014, 2250, 2656,  232, 3272,  181, 4890, 3320,\n",
      "        4363, 1465, 2409,  113, 5925, 4348, 5381, 2156, 5380, 1091, 5383, 4141,\n",
      "        5848, 3424, 2565, 5841, 5050, 2731,  708,  142,  365,  404, 3000, 1471,\n",
      "        5816,  677, 4309,  290, 1510, 5939, 2843, 2298, 3725,  141, 2496, 1430,\n",
      "        1741, 2978, 5206, 5820, 2880,  535, 5026,  437,  291, 3708,  983, 4030,\n",
      "        3499, 2196,  855, 3347, 2229, 2121, 4856, 2485, 4361,    9, 2989, 2524,\n",
      "        5482, 1160, 4591,  783, 2697, 3810, 4446, 5129, 5956, 1296, 2366, 3101,\n",
      "        3295, 3665, 1369, 5983, 2546,  884,  797, 4967, 4228, 5587, 5144, 2048,\n",
      "        3768,  944,  665, 3865, 3891,  720, 3213, 5435])\n"
     ]
    }
   ],
   "source": [
    "print(user_id.shape)\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 200])\n",
      "tensor([3528,   31, 3436,  605, 1726, 1609,  277,  458, 2264, 3270, 3437, 2005,\n",
      "           2, 2021, 1702,  541, 1344, 1748, 2672, 3476, 1258, 1997, 1994, 3499,\n",
      "        1982, 2455, 1407, 2710, 1332, 2459, 1347, 1339, 1974, 1327,  879, 2004,\n",
      "        1762,  742, 2121, 2513, 2717,  196, 1970, 2122, 1977, 2315, 1380, 1088,\n",
      "        1086, 1964, 1459, 1625, 2583, 1092, 1464, 1892, 2752,  695, 2413,  924,\n",
      "        1247,  377,  802, 1059, 3479, 3501, 1216, 2581, 2340, 1755,  289, 1835,\n",
      "         249,  163,  461,  236, 2802, 2369, 3394, 2875,  804, 2950, 1556,  750,\n",
      "        1199, 1240, 2010,  589,  198, 2407, 2527, 1921, 1603,  316,  185,  442,\n",
      "        3033,  611, 3354, 1037,  172,  256,  880, 2701, 1882,  319,  373, 3147,\n",
      "        2819, 1834, 2391, 3203, 3102, 3518, 3505, 2118,  832, 3176, 3101, 2058,\n",
      "        3555, 2707, 2353, 1608,  422,  490, 1722,   16, 3686, 3005, 1422, 2273,\n",
      "         376, 1518, 3370, 3219, 2881, 1597,  230, 1438, 2956, 1047, 3557, 2803,\n",
      "         225, 1686, 1687, 2561, 2263, 2505, 1658,   23, 3316,  415,   79, 2605,\n",
      "         782, 1831, 1752, 1299, 2402, 2404, 1266, 3671,  383,  416,  648, 1573,\n",
      "         553, 3571, 3481,  951, 3626, 2997, 2249, 2861, 2912, 3115, 3717, 2433,\n",
      "        3683, 1542, 2826, 2976, 3007, 3755, 3785, 3752, 3646, 3825, 3616, 3826,\n",
      "        3827, 3793, 3298, 1136, 1080, 2443, 2731,  423])\n"
     ]
    }
   ],
   "source": [
    "print(historical_ids.shape)\n",
    "print(historical_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 200])\n",
      "tensor([3, 2, 2, 2, 1, 3, 2, 3, 2, 4, 1, 1, 2, 2, 1, 4, 2, 3, 3, 4, 4, 4, 1, 3,\n",
      "        3, 1, 3, 4, 2, 2, 2, 1, 3, 3, 3, 1, 2, 1, 1, 3, 1, 2, 3, 1, 1, 1, 3, 2,\n",
      "        3, 3, 3, 5, 3, 3, 4, 3, 2, 3, 1, 5, 3, 4, 2, 4, 3, 4, 3, 3, 1, 3, 3, 3,\n",
      "        3, 2, 3, 1, 2, 2, 2, 1, 3, 1, 1, 5, 4, 4, 3, 4, 3, 3, 4, 3, 2, 2, 2, 2,\n",
      "        2, 1, 4, 2, 1, 2, 2, 2, 1, 3, 4, 4, 5, 3, 4, 3, 3, 2, 4, 3, 3, 4, 3, 3,\n",
      "        4, 4, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3, 2,\n",
      "        3, 3, 2, 3, 3, 3, 3, 1, 2, 1, 3, 3, 3, 3, 2, 4, 3, 2, 3, 4, 3, 1, 2, 4,\n",
      "        3, 4, 3, 1, 1, 3, 2, 4, 4, 3, 4, 5, 4, 2, 2, 4, 5, 4, 2, 3, 2, 2, 4, 1,\n",
      "        4, 5, 5, 1, 2, 4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(historical_ratings.shape)\n",
    "print(historical_ratings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 200])\n",
      "tensor([963617959, 963617985, 963617985, 963617985, 963618003, 963618093,\n",
      "        963618093, 963618093, 963618116, 963618136, 963618179, 963618179,\n",
      "        963618179, 963618196, 963618216, 963618266, 963618299, 963618331,\n",
      "        963618350, 963618375, 963618375, 963618414, 963618414, 963618414,\n",
      "        963618414, 963618414, 963618450, 963618450, 963618495, 963618565,\n",
      "        963618565, 963618583, 963618583, 963618600, 963618600, 963618648,\n",
      "        963618648, 963618648, 963618670, 963618670, 963618670, 963618693,\n",
      "        963618693, 963618729, 963618748, 963618760, 963618781, 963618781,\n",
      "        963618781, 963618815, 963618815, 963618987, 963619024, 963619071,\n",
      "        963619071, 963619071, 963619099, 963619099, 963619099, 963619129,\n",
      "        963619129, 963619129, 963619129, 963619129, 963619129, 963619153,\n",
      "        963619153, 963619181, 963619181, 963619181, 963619246, 963619246,\n",
      "        963619246, 963619246, 963619246, 963619246, 963619289, 963619289,\n",
      "        963619289, 963619335, 963619335, 963619335, 963619335, 963619365,\n",
      "        963619365, 963619416, 963619416, 963619417, 963619434, 963619452,\n",
      "        963619540, 963619540, 963619567, 963619567, 963619567, 963619600,\n",
      "        963619642, 963619657, 963619657, 963619679, 963619701, 963619701,\n",
      "        963619729, 963619729, 963619729, 963619743, 963619771, 963619771,\n",
      "        963619771, 963619786, 963619807, 963619824, 963619845, 963619871,\n",
      "        963619908, 963619929, 963619954, 963619954, 963619975, 963620091,\n",
      "        963620091, 963678663, 963678683, 963678734, 963678749, 963678831,\n",
      "        963678850, 963678850, 963678869, 963679358, 963679419,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0,         0,         0,         0,         0,\n",
      "                0,         0])\n"
     ]
    }
   ],
   "source": [
    "print(historical_timestamps.shape)\n",
    "print(historical_timestamps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([200, 131, 200, 200,  30, 130,  35,  75,  21, 200, 200, 190, 200,  20,\n",
      "         20, 200, 200,  24,  56, 124, 200, 110, 200,  99,  71,  26, 142,  35,\n",
      "        169,  66, 131,  89, 200, 200, 170, 200, 191, 200, 133,  67, 196,  23,\n",
      "         23, 200,  19,  32,  27, 200, 200,  70, 200, 200,  84, 200,  19,  46,\n",
      "         46,  49, 105,  26,  31, 200, 131,  32,  32, 110,  38, 119,  25,  22,\n",
      "        200, 115, 200, 172,  28,  47, 200,  20, 200,  51, 101,  34,  77, 123,\n",
      "        200,  35, 200,  44,  38, 190,  78, 200, 131, 105, 104,  25, 200, 106,\n",
      "        200, 118,  33,  66, 200, 109, 200,  47,  40, 200,  73, 200, 200,  27,\n",
      "        117,  98,  82, 103,  22,  54,  31,  34, 200,  44,  19,  56,  99, 200,\n",
      "        136,  45])\n",
      "tensor(200)\n"
     ]
    }
   ],
   "source": [
    "print(history_lengths.shape)\n",
    "print(history_lengths)\n",
    "print(max(history_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([ 224,  194, 1817, 3379, 2976, 2877, 3565, 1208, 1573, 2020, 3428, 3624,\n",
      "        2798, 2000, 2245, 2537, 2735,   61, 3624,    1, 2460, 3638, 3868, 3831,\n",
      "        3363, 1938, 1682,  260,  508, 3717, 3510, 2539, 3394, 2329, 1393, 2119,\n",
      "        1627, 2633,  594, 3895, 2858, 1162, 2915,  393, 3174,   89,  260,  736,\n",
      "         432, 3510, 3512,  278, 3299, 3422, 3753, 3160,  593, 3498, 3394, 3173,\n",
      "        1589, 2414, 3826, 2671, 1976, 3534, 3846, 2399, 2959, 2203, 1303, 3534,\n",
      "         900,  978, 3623, 3361, 2361, 2987,  193, 3062, 3194,  370, 2408, 2529,\n",
      "        2401, 2918,  574, 1784, 3869, 2300, 1282, 3566,  596, 2294, 1376, 1240,\n",
      "        3614, 1623,   36,  673, 3793, 3753, 3442, 1358,  469, 1225, 1586, 1394,\n",
      "        2427, 2502, 3310, 2657, 3555, 1784,  933, 3408, 1121, 2501,  587,  541,\n",
      "        3000,  608, 1529, 1381, 1962, 2006, 2791,  780])\n"
     ]
    }
   ],
   "source": [
    "print(target_ids.shape)\n",
    "print(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([3, 4, 2, 5, 2, 4, 2, 2, 5, 4, 4, 1, 1, 5, 4, 4, 3, 5, 2, 5, 2, 3, 5, 4,\n",
      "        4, 5, 5, 4, 5, 1, 5, 3, 4, 5, 1, 2, 3, 5, 5, 4, 1, 5, 5, 1, 3, 3, 5, 4,\n",
      "        1, 5, 4, 4, 3, 3, 5, 4, 4, 4, 1, 4, 3, 4, 4, 3, 1, 2, 5, 3, 5, 5, 5, 2,\n",
      "        4, 4, 3, 2, 5, 3, 1, 5, 4, 3, 5, 5, 5, 5, 3, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
      "        4, 3, 4, 1, 5, 5, 2, 4, 3, 4, 3, 4, 1, 4, 4, 5, 3, 3, 5, 4, 1, 4, 5, 5,\n",
      "        4, 5, 5, 2, 4, 3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "print(target_ratings.shape)\n",
    "print(target_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor([1004157486,  963679456, 1045945209,  976767198,  966630460,  996013330,\n",
      "         961607747,  977594963,  969851412,  959307449, 1028484729,  971207165,\n",
      "         965106162,  974058435,  965779263,  974714308,  974742329,  974668725,\n",
      "         976063550,  958780306,  958346936,  970569489,  966208724,  983261337,\n",
      "         971763054,  981396825,  974778511,  975277867, 1013919102,  974596713,\n",
      "         973531630,  976812993,  971259833,  977090747,  962740382,  970861825,\n",
      "         965186085,  974768388, 1008704143,  977507389,  959813284,  965485145,\n",
      "         960928975,  974632776,  960393128,  974930258,  960355691,  965353589,\n",
      "         957786029,  975562172,  996354648, 1044278237,  983492567,  973244412,\n",
      "         975542365,  980559291,  976405459,  988503219,  970622299,  974753669,\n",
      "         957915227,  975612817,  967745970,  976564993,  974749071,  957216463,\n",
      "         972545479,  974500216,  966218328,  977357662,  974435367,  974761580,\n",
      "         974712244,  970968986,  961631084,  957905737,  989193378,  976139053,\n",
      "         962777773,  976278578,  976566636,  966278986,  975102451, 1005260879,\n",
      "         967235442,  974606472,  976426500,  967757542,  974598346,  974648496,\n",
      "         962831789, 1026162329,  984248355,  978226678,  970889766,  974064506,\n",
      "         960389779, 1008037748, 1043098094,  984413508,  973307050,  965959816,\n",
      "         965543305,  962134982, 1033358097,  974788897,  974340915,  970451909,\n",
      "         968058359,  993858805, 1014452808,  956926305,  974041748, 1019867821,\n",
      "         975414356,  967979539,  965313622,  959283008,  962035935,  974664355,\n",
      "        1000878176,  975166514,  975645741,  965853716,  965802744,  975530188,\n",
      "         968520476,  960062286])\n"
     ]
    }
   ],
   "source": [
    "print(target_timestamps.shape)\n",
    "print(target_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model and moves it to GPU with id rank\n",
    "device = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features, target_ids, target_ratings = movielens_seq_features_from_row(\n",
    "    batch,\n",
    "    device=device,\n",
    "    max_output_length=gr_output_length + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1])\n",
      "tensor([[ 224],\n",
      "        [ 194],\n",
      "        [1817],\n",
      "        [3379],\n",
      "        [2976]], device='cuda:0')\n",
      "torch.Size([128, 1])\n",
      "tensor([[3],\n",
      "        [4],\n",
      "        [2],\n",
      "        [5],\n",
      "        [2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(target_ids.shape)\n",
    "print(target_ids[:5])\n",
    "print(target_ratings.shape)\n",
    "print(target_ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128, 211])\n",
      "None\n",
      "torch.Size([128, 211])\n",
      "torch.Size([128, 211])\n"
     ]
    }
   ],
   "source": [
    "print(seq_features.past_lengths.shape)\n",
    "print(seq_features.past_ids.shape)\n",
    "print(seq_features.past_embeddings.shape if seq_features.past_embeddings else None)\n",
    "print(seq_features.past_payloads[\"timestamps\"].shape)\n",
    "print(seq_features.past_payloads[\"ratings\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "print(dataset.max_item_id)\n",
    "print(item_embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize _item_emb.weight as truncated normal: torch.Size([3953, 240]) params\n"
     ]
    }
   ],
   "source": [
    "embedding_module: EmbeddingModule = LocalEmbeddingModule(\n",
    "    num_items=dataset.max_item_id,\n",
    "    item_embedding_dim=item_embedding_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_item_emb.weight: torch.Size([3953, 240])\n"
     ]
    }
   ],
   "source": [
    "for name, params in embedding_module.named_parameters():\n",
    "    print(f\"{name}: {params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "B, N = seq_features.past_ids.shape\n",
    "print(B)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3528,   31, 3436,  ...,    0,    0,    0],\n",
       "        [1711, 1254, 1196,  ...,    0,    0,    0],\n",
       "        [1278, 2394,  899,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [1201, 1222, 2366,  ...,    0,    0,    0],\n",
       "        [ 480, 1777, 2359,  ...,    0,    0,    0],\n",
       "        [1358, 1230,  480,  ...,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_features.past_ids.scatter_(\n",
    "    dim=1,\n",
    "    index=seq_features.past_lengths.view(-1, 1),\n",
    "    src=target_ids.view(-1, 1),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
